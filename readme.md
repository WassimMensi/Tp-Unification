# ğŸ“¦ TP3

## ETAPE 1 : Mise en place dâ€™une architecture de gÃ©nÃ©ration de logs avec Docker

Cette premiÃ¨re partie du TP a consistÃ© Ã  simuler une infrastructure web composÃ©e de plusieurs serveurs, chacun gÃ©nÃ©rant des logs dans un format diffÃ©rent, en prÃ©paration dâ€™une future ingestion avec lâ€™ELK Stack.

### ğŸ¯ Objectifs atteints

- DÃ©ployer trois serveurs web avec Docker :
  - ğŸ”µ Un serveur **Apache**
  - ğŸŸ¢ Un serveur **Nginx**
  - ğŸŸ£ Un serveur personnalisÃ© (Node.js) gÃ©nÃ©rant des **logs en JSON**
- Utiliser `docker-compose` pour orchestrer les conteneurs
- Monter des **volumes** locaux pour stocker les fichiers de logs produits
- GÃ©nÃ©rer des logs cÃ´tÃ© client avec `curl` ou navigateur
- VÃ©rifier les fichiers de logs localement dans `./logs/`

### ğŸ—‚ï¸ Arborescence du projet

TP3/  
â”œâ”€â”€ apache/ # Dockerfile Apache  
â”œâ”€â”€ nginx/ # Dockerfile Nginx  
â”œâ”€â”€ custom-web/ # Dockerfile + app.js Node.js  
â”œâ”€â”€ logs/ # Volumes montÃ©s pour accÃ©der aux logs  
â”‚ â”œâ”€â”€ apache/  
â”‚ â”œâ”€â”€ nginx/  
â”‚ â””â”€â”€ custom/  
â”œâ”€â”€ docker-compose.yml  
â””â”€â”€ readmeTP3.md  

### âš™ï¸ Fonctionnement

- Chaque conteneur expose un port :
  - Apache : `http://localhost:8081`
  - Nginx : `http://localhost:8082`
  - Custom : `http://localhost:8083`
- Les logs sont gÃ©nÃ©rÃ©s automatiquement Ã  chaque requÃªte
- Les fichiers de logs sont disponibles dans le dossier `logs/` ainsi que dans Docker Desktop (stdout) ğŸ”§ *PossibilitÃ© d'ajouter une config `httpd.conf` personnalisÃ©e pour Ã©crire les logs apache sur disque si besoin.*

### âœ… Statut

Environnement fonctionnel et prÃªt Ã  Ãªtre connectÃ© Ã  :
- **Filebeat**
- **Logstash**
- ou **Elasticsearch directement**  

## ETAPE 2 : Unification de logs de serveurs web dans Elastic Stack

### ğŸ¯ Objectifs

Ã€ la fin de ce TP, vous serez capable de :
- Mettre en place un environnement Elastic Stack complet localement
- Configurer Filebeat pour collecter des logs de diffÃ©rents serveurs web
- CrÃ©er une pipeline Logstash pour normaliser et enrichir les logs
- Configurer une Ingest Pipeline dans Elasticsearch
- Configurer Metricbeat pour collecter des mÃ©triques systÃ¨me
- Explorer les donnÃ©es unifiÃ©es dans Kibana
- CrÃ©er des dashboards pour visualiser logs et mÃ©triques

### ğŸ› ï¸ PrÃ©requis

- Docker & Docker Compose installÃ©s
- 4 GB de RAM minimum
- Terminal et Ã©diteur de texte
- Architecture supportÃ©e (x86_64 ou ARM64)

### â±ï¸ DurÃ©e estimÃ©e

3 Ã  4 heures

---

### ğŸ—‚ï¸ Architecture cible

Apache Nginx Custom Web  
â”‚ â”‚ â”‚  
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  
â”‚ â”‚  
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”  
â”‚Filebeatâ”‚ â”‚Metricbeatâ”‚  
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  
â”‚ â”‚  
â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”  
â”‚ Logstash â”‚  
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  
â”‚  
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  
â”‚Elasticsearchâ”‚  
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  
â”‚  
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”  
â”‚ Kibana â”‚  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  

---

### ğŸ”§ Plan du TP

#### 1. Mise en place de lâ€™environnement
- CrÃ©ation dâ€™un fichier `docker-compose.yml` pour dÃ©ployer :
  - Elasticsearch, Kibana, Logstash, Filebeat, Metricbeat
  - Trois serveurs de logs (Apache, Nginx, Custom Web)

#### 2. GÃ©nÃ©ration de logs simulÃ©s
- Fichiers `log-generator.sh` configurÃ©s pour chaque serveur
- `httpd.conf` pour Apache et `nginx.conf` pour Nginx

#### 3. Configuration de Filebeat
- Activation des modules Apache et Nginx
- Fichier `filebeat.yml` pour dÃ©clarer les inputs et lâ€™output vers Logstash

#### 4. Configuration de Metricbeat
- Module `system` pour collecter CPU, mÃ©moire, I/O, etc.
- Module `docker` pour observer l'activitÃ© des conteneurs

#### 5. Configuration de Logstash
- Pipeline `unified-logs.conf` pour mapper et enrichir les logs (mutate, ruby, geoip, user_agentâ€¦)

#### 6. Ingest Pipeline Elasticsearch
- Script `setup-ingest-pipeline.sh` exÃ©cutÃ© via conteneur `curl`
- CrÃ©ation dâ€™un index template pour les logs enrichis

#### 7. Lancement & vÃ©rification
- Commande :
  ```bash
  docker-compose up -d

**âœ… RÃ©ponses/Validation d'Ã©tape :**  
![Verification du nombre de documents dans l'index](./docker-compose.png)


AccÃ¨s Ã  Kibana : http://localhost:5601

CrÃ©ation de Data Views pour unified-logs-* et metricbeat-*

**âœ… RÃ©ponses/Validation d'Ã©tape :**  

J'ai rÃ©alisÃ© les data_views :  
![Verification du nombre de documents dans l'index](./data_views.png)

J'ai rÃ©alisÃ© diffÃ©rentes requÃªtes pour filtrer les logs :  
![Verification du nombre de documents dans l'index](./test1_ip.png)

#### 8. CrÃ©ation de dashboards  

Nous avons rÃ©alisÃ© diffÃ©rents tests et manipulations (voir screenshots ci-dessous).  

Dashboard Logs unifiÃ©s HTTP Status Codes (Pie Chart)

**âœ… RÃ©ponses/Validation d'Ã©tape :**  

![Verification du nombre de documents dans l'index](./camembert_test.png)

Activity by Server (Bar horizontal)

**âœ… RÃ©ponses/Validation d'Ã©tape :**  

![Verification du nombre de documents dans l'index](./server_activities.png)

Traffic Over Time (Line chart par mÃ©thode HTTP)

**âœ… RÃ©ponses/Validation d'Ã©tape :**  

![Verification du nombre de documents dans l'index](./graphique_ligne_requete_par_minutes.png)

Visitor Map (Map gÃ©o IP)
**âœ…**  

Top Pages (Tableau des URLs les plus accÃ©dÃ©es)
**âœ…**  

Dashboard MÃ©triques
**âœ…**  

CPU Usage (Line chart)

**âœ… RÃ©ponses/Validation d'Ã©tape :**  

![Verification du nombre de documents dans l'index](./cpu_usage.png)

Memory Usage (Gauge)

**âœ… RÃ©ponses/Validation d'Ã©tape :**  

![Verification du nombre de documents dans l'index](./gauge.png)

Network Activity (Area chart IN/OUT)

**âœ… RÃ©ponses/Validation d'Ã©tape :**  

![Verification du nombre de documents dans l'index](./network_activity.jpg)

#### 9. Extensions avancÃ©es (optionnelles)
CrÃ©ation dâ€™alertes sur erreurs 5xx, CPU Ã©levÃ©â€¦

IntÃ©gration Machine Learning (si licence)

IntÃ©gration APM

#### 10. Nettoyage

docker-compose down -v
ğŸ§ª RÃ©solution de problÃ¨mes
ProblÃ¨me	Solution
Elasticsearch ne dÃ©marre pas	Baisser ES_JAVA_OPTS Ã  -Xms256m -Xmx256m
Logs non visibles dans Kibana	VÃ©rifier Filebeat et Logstash (docker logs ...)
MÃ©triques absentes	VÃ©rifier Metricbeat et sa configuration Docker

### âœ… Conclusion
Au terme de ce TP, vous avez :

DÃ©ployÃ© lâ€™Elastic Stack complet avec Docker

CollectÃ© et enrichi des logs simulÃ©s de 3 serveurs

CrÃ©Ã© des pipelines de traitement normalisÃ© avec Logstash

ConfigurÃ© des dashboards avancÃ©s dans Kibana

Vous avez maintenant une base solide pour la supervision de systÃ¨mes distribuÃ©s avec Elastic Stack.
Pour aller plus loin :

Explorez KQL (Kibana Query Language)

Ajoutez dâ€™autres sources de logs (DB, pare-feuâ€¦)

Mettez en place des alertes, rÃ´les utilisateurs, et dashboard en production

## Etape 3 : Comparaison des principales diffÃ©rences avec correction

Diff 1 : Nous avons bypassÃ© l'Ã©tape logstash.  
Diff 2 : Ce qu'on a fait dans le pipeline de logstash (unified-log) Ã  Ã©tÃ© fait directement dans le docker-compose dans la correction.  